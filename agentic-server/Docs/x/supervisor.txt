# app/agents/supervisor.py

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Dict, Any, Optional
from langchain_google_genai import ChatGoogleGenerativeAI
import os
from ..config import GOOGLE_API_KEY
from ..tools.search_tools import all_tools
from ..schemas.demo_report import DemoReport
from ..schemas.standard_report import StandardReport
from ..utils.logger import get_logger
from datetime import datetime

os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY

logger = get_logger(__name__)
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash")

# ---------------- Agent State ---------------- #

class AgentState(TypedDict):
    conversation_history: str
    sentiment_risk: Optional[Dict]
    screening_scores: Optional[Dict]
    summary: Optional[Dict]
    resource_categories: Optional[Dict]
    retrieved_resources: Optional[List[Dict]]
    final_report: Optional[Dict]

# ---------------- Agent Functions ---------------- #

async def sentiment_risk_agent(state: AgentState) -> Dict[str, Any]:
    logger.info("Running Sentiment & Risk Analyzer Agent...")
    sentiment = "negative"
    emotional_intensity = "high"
    risk_level = "medium"
    red_flags = ["stress", "anxiety", "isolation"]
    logger.info(f"Sentiment Analysis: {sentiment}, {emotional_intensity}, {risk_level}, {red_flags}")
    state["sentiment_risk"] = {"sentiment": sentiment, "emotional_intensity": emotional_intensity, "risk_level": risk_level, "red_flags": red_flags}
    return state

async def screening_agent(state: AgentState) -> Dict[str, Any]:
    logger.info("Running Screening Agent...")
    phq_9, gad_7, ghq = 12, 14, 20
    state["screening_scores"] = {"phq_9": phq_9, "gad_7": gad_7, "ghq": ghq}
    logger.info(f"Screening Scores: {state['screening_scores']}")
    return state

async def conversation_summarizer_agent(state: AgentState) -> Dict[str, Any]:
    logger.info("Running Conversation Summarizer Agent...")
    chat_summary = "The student is feeling overwhelmed and stressed about upcoming exams..."
    key_points = ["Student is overwhelmed by exams", "Sleep difficulties", "Trouble focusing", "Fear of failing", "Feeling alone"]
    student_expressed_concerns = ["Feeling overwhelmed", "Inability to sleep", "Difficulty focusing", "Fear of failing", "Feeling alone"]
    state["summary"] = {"chat_summary": chat_summary, "key_points": key_points, "student_expressed_concerns": student_expressed_concerns}
    return state

async def recommendation_agent(state: AgentState) -> Dict[str, Any]:
    logger.info("Running Recommendation Agent...")
    recommended_categories = ["Mental Health Counseling/Therapy", "Stress and Anxiety Management", "Academic Support and Study Skills", "Sleep Improvement Resources", "Social Connection and Peer Support"]
    justification = "Multi-faceted recommendation based on sentiment and screening results."
    state["resource_categories"] = {"recommended_categories": recommended_categories, "justification": justification}
    return state

def resource_retrieval_agent(state: AgentState) -> Dict[str, Any]:
    logger.info("Running Resource Retrieval Agent...")
    categories = state["resource_categories"]["recommended_categories"]
    concerns = state["summary"]["student_expressed_concerns"]
    query = f"Find resources about {', '.join(concerns)} focusing on {', '.join(categories)}"

    prompt = ChatPromptTemplate.from_messages([
        ("system", "You are a resource retrieval agent. Use tools to find relevant resources."),
        ("user", "{input}\n\n{agent_scratchpad}")
    ])

    agent = create_tool_calling_agent(llm, all_tools, prompt)
    executor = AgentExecutor(agent=agent, tools=all_tools, verbose=True)
    result = executor.invoke({"input": query})

    structured_resources = []
    raw = result.get("output", "")
    if isinstance(raw, str):
        structured_resources.append({"title": "Retrieved Resources", "url": "", "category": "General", "content": raw})
    elif isinstance(raw, list):
        for r in raw:
            structured_resources.append({"title": r.get("title", r.get("content", "")), "url": r.get("url", ""), "category": r.get("category", "General"), "content": r.get("content", "")})

    state["retrieved_resources"] = structured_resources
    logger.info(f"Retrieved Resources: {structured_resources}")
    return state

def report_generator(state: AgentState) -> Dict[str, Any]:
    logger.info("Running Report Generator Agent...")
    now = datetime.utcnow().isoformat()
    demo_report = {"student_summary": state["summary"]["chat_summary"], "stress_level": "High", "key_findings": state["summary"]["key_points"], "helpful_resources": state.get("retrieved_resources", [])}
    standard_report = {"chat_summary": state["summary"]["chat_summary"], "risk_assessment": state["sentiment_risk"], "screening_scores": state["screening_scores"], "recommendations": state.get("retrieved_resources", []), "report_generated_at": now}
    state["final_report"] = {"demo_report": demo_report, "standard_report": standard_report}
    return state

# ---------------- Graph Orchestration ---------------- #

def build_graph():
    workflow = StateGraph(AgentState)
    workflow.add_node("sentiment_risk", sentiment_risk_agent)
    workflow.add_node("screening", screening_agent)
    workflow.add_node("summarizer", conversation_summarizer_agent)
    workflow.add_node("recommender", recommendation_agent)
    workflow.add_node("retriever", resource_retrieval_agent)
    workflow.add_node("report_generator", report_generator)

    workflow.set_entry_point("sentiment_risk")
    workflow.add_edge("sentiment_risk", "screening")
    workflow.add_edge("screening", "summarizer")
    workflow.add_edge("summarizer", "recommender")
    workflow.add_edge("recommender", "retriever")
    workflow.add_edge("retriever", "report_generator")
    workflow.add_edge("report_generator", END)

    app = workflow.compile()
    return app

graph_app = build_graph()
